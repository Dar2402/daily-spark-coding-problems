{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33eec3f6-638b-4534-aa80-3b0cca02190a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as F, Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbf0908a-5a68-4d89-9bb3-00684bdd775b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"DailyCodingProblem\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed93eeb-7935-4bf8-9e14-9edbc2441d3a",
   "metadata": {},
   "source": [
    "# ðŸ“ Problem 1: PySpark â€“ Detect Missing Dates in a Time Series\n",
    "\n",
    "### **Problem Statement**\n",
    "\n",
    "You are given a PySpark DataFrame containing daily sales records. However, some dates are missing. Write a PySpark program to **identify all the missing dates** within the given range of dates.\n",
    "\n",
    "### **Sample Input** (DataFrame `sales`)\n",
    "\n",
    "| date       | sales |\n",
    "| ---------- | ----- |\n",
    "| 2025-01-01 | 100   |\n",
    "| 2025-01-02 | 150   |\n",
    "| 2025-01-04 | 120   |\n",
    "| 2025-01-06 | 200   |\n",
    "\n",
    "### **Expected Output**\n",
    "\n",
    "| missing\\_date |\n",
    "| ------------- |\n",
    "| 2025-01-03    |\n",
    "| 2025-01-05    |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "636430c3-a7f1-42f9-9efb-05922b0fea80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|missing_dates|\n",
      "+-------------+\n",
      "|   2025-01-03|\n",
      "|   2025-01-05|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "  {\n",
    "    \"date\": \"2025-01-01\",\n",
    "    \"sales\": 100\n",
    "  },\n",
    "  {\n",
    "    \"date\": \"2025-01-02\",\n",
    "    \"sales\": 150\n",
    "  },\n",
    "  {\n",
    "    \"date\": \"2025-01-04\",\n",
    "    \"sales\": 120\n",
    "  },\n",
    "  {\n",
    "    \"date\": \"2025-01-06\",\n",
    "    \"sales\": 200\n",
    "  }\n",
    "]\n",
    "\n",
    "\n",
    "df = spark.createDataFrame(data)\n",
    "\n",
    "df = df.withColumn(\n",
    "  \"actual_date\",\n",
    "  F.to_date(F.col(\"date\"))\n",
    ")\n",
    "\n",
    "date_bounds = df.select(\n",
    "    F.min(\"actual_date\").alias(\"min_date\"),\n",
    "    F.max(\"actual_date\").alias(\"max_date\")\n",
    ")\n",
    "\n",
    "first_row = date_bounds.first()\n",
    "first_date = first_row[\"min_date\"]\n",
    "\n",
    "\n",
    "last_row = date_bounds.first()\n",
    "last_date = last_row[\"max_date\"]\n",
    "\n",
    "date_sequence_df = spark.range(1).withColumn(\n",
    "  \"full_range\", \n",
    "  F.sequence(F.lit(first_date), F.lit(last_date), F.expr(\"INTERVAL 1 DAY\"))\n",
    ")\n",
    "date_sequence_df = date_sequence_df.select(\"full_range\")\n",
    "date_sequence_df = date_sequence_df.withColumn(\n",
    "  \"full_range\",\n",
    "  F.explode(F.col(\"full_range\"))\n",
    ")\n",
    "\n",
    "missing_dates_df = date_sequence_df.join(\n",
    "  df,\n",
    "  date_sequence_df.full_range == df.actual_date,\n",
    "  \"left_anti\"\n",
    ").withColumnRenamed(\n",
    "  \"full_range\",\n",
    "  \"missing_dates\"\n",
    ")\n",
    "\n",
    "missing_dates_df = missing_dates_df.orderBy(F.asc(F.col(\"missing_dates\")))\n",
    "\n",
    "missing_dates_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d9451f-9870-4d2d-a8e9-c2f57569d860",
   "metadata": {},
   "source": [
    "# ðŸ“ Problem 2: SQL â€“ Find the Longest Streak of Active Days per User\n",
    "\n",
    "### **Problem Statement**\n",
    "\n",
    "You are given a SQL table `user_logins(user_id, login_date)`. Write a SQL query to find the **longest streak of consecutive login days** for each user.\n",
    "\n",
    "### **Sample Input** (`user_logins`)\n",
    "\n",
    "| user\\_id | login\\_date |\n",
    "| -------- | ----------- |\n",
    "| 1        | 2025-01-01  |\n",
    "| 1        | 2025-01-02  |\n",
    "| 1        | 2025-01-04  |\n",
    "| 2        | 2025-01-01  |\n",
    "| 2        | 2025-01-02  |\n",
    "| 2        | 2025-01-03  |\n",
    "| 2        | 2025-01-05  |\n",
    "\n",
    "### **Expected Output**\n",
    "\n",
    "| user\\_id | longest\\_streak |\n",
    "| -------- | --------------- |\n",
    "| 1        | 2               |\n",
    "| 2        | 3               |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9bd16dd-d046-4609-a2bd-a17b7ba4e6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\"user_id\": 1, \"login_date\": \"2025-01-01\"},\n",
    "    {\"user_id\": 1, \"login_date\": \"2025-01-02\"},\n",
    "    {\"user_id\": 1, \"login_date\": \"2025-01-04\"},\n",
    "    {\"user_id\": 2, \"login_date\": \"2025-01-01\"},\n",
    "    {\"user_id\": 2, \"login_date\": \"2025-01-02\"},\n",
    "    {\"user_id\": 2, \"login_date\": \"2025-01-03\"},\n",
    "    {\"user_id\": 2, \"login_date\": \"2025-01-05\"},\n",
    "]\n",
    "\n",
    "\n",
    "df = spark.createDataFrame(data)\n",
    "\n",
    "df = df.withColumn(\n",
    "  \"login_date\",\n",
    "  F.to_date(F.col(\"login_date\"))\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a789b04-35bc-4277-bf53-92478df0d51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- login_date: date (nullable = true)\n",
      " |-- user_id: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae5a476f-3e10-4689-9136-36836bfaba0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Window.partitionBy(\"user_id\").orderBy(\"login_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a109060-c716-4b51-96e1-cf98a748a86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+\n",
      "|user_id|longest_streak|\n",
      "+-------+--------------+\n",
      "|      1|             2|\n",
      "|      2|             3|\n",
      "+-------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"prev_date\", F.lag(\"login_date\").over(w)) \\\n",
    "       .withColumn(\"gap\", F.when(F.datediff(\"login_date\", F.col(\"prev_date\")) > 1, 1).otherwise(0))\n",
    "\n",
    "\n",
    "df = df.filter(F.col(\"gap\") == 0)\n",
    "\n",
    "\n",
    "\n",
    "df = df.groupby(\"user_id\").agg(\n",
    "    F.count(\"user_id\").alias(\"longest_streak\")\n",
    ")\n",
    "\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b307447d-f5f4-45de-b807-69dbcd413cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
