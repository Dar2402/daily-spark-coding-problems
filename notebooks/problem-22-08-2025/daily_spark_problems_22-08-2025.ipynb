{
 "cells": [
  {
   "cell_type": "code",
   "id": "33eec3f6-638b-4534-aa80-3b0cca02190a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T12:27:40.912809Z",
     "start_time": "2025-08-22T12:27:40.905278Z"
    }
   },
   "source": [
    "from pyspark.sql import SparkSession, functions as F, Window as W\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DateType, IntegerType"
   ],
   "outputs": [],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "id": "fbf0908a-5a68-4d89-9bb3-00684bdd775b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T12:27:41.472703Z",
     "start_time": "2025-08-22T12:27:41.460029Z"
    }
   },
   "source": "spark = SparkSession.builder.appName(\"DailyCodingProblem-22-08-2025\").getOrCreate()",
   "outputs": [],
   "execution_count": 51
  },
  {
   "cell_type": "markdown",
   "id": "3ed93eeb-7935-4bf8-9e14-9edbc2441d3a",
   "metadata": {},
   "source": [
    "# ðŸ“ Problem 1: PySpark â€“ Detect Outlier Transactions per Day\n",
    "\n",
    "### **Problem Statement**\n",
    "\n",
    "You have a PySpark DataFrame with daily transaction amounts. For each day, identify **transactions greater than the average amount for that day** (outliers).\n",
    "\n",
    "### **Sample Input** (`transactions`)\n",
    "\n",
    "| txn\\_date  | txn\\_id | amount |\n",
    "| ---------- | ------- | ------ |\n",
    "| 2025-01-01 | T1      | 100    |\n",
    "| 2025-01-01 | T2      | 200    |\n",
    "| 2025-01-01 | T3      | 500    |\n",
    "| 2025-01-02 | T4      | 300    |\n",
    "| 2025-01-02 | T5      | 400    |\n",
    "| 2025-01-02 | T6      | 600    |\n",
    "\n",
    "### **Expected Output**\n",
    "\n",
    "| txn\\_date  | txn\\_id | amount |\n",
    "| ---------- | ------- | ------ |\n",
    "| 2025-01-01 | T3      | 500    |\n",
    "| 2025-01-02 | T6      | 600    |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "id": "636430c3-a7f1-42f9-9efb-05922b0fea80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T12:27:44.620667Z",
     "start_time": "2025-08-22T12:27:44.127499Z"
    }
   },
   "source": [
    "schema = StructType([\n",
    "    StructField(\"txn_date\", StringType(), True),\n",
    "    StructField(\"txn_id\", StringType(), True),\n",
    "    StructField(\"amount\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "data = [\n",
    "    (\"2025-01-01\", \"T1\", 100),\n",
    "    (\"2025-01-01\", \"T2\", 200),\n",
    "    (\"2025-01-01\", \"T3\", 500),\n",
    "    (\"2025-01-02\", \"T4\", 300),\n",
    "    (\"2025-01-02\", \"T5\", 400),\n",
    "    (\"2025-01-02\", \"T6\", 600),\n",
    "]\n",
    "\n",
    "\n",
    "df = spark.createDataFrame(data, schema=schema)\n",
    "df = df.withColumn(\n",
    "    'txn_date',\n",
    "    F.to_date(F.col(\"txn_date\"))\n",
    ")\n",
    "df.show()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+------+\n",
      "|  txn_date|txn_id|amount|\n",
      "+----------+------+------+\n",
      "|2025-01-01|    T1|   100|\n",
      "|2025-01-01|    T2|   200|\n",
      "|2025-01-01|    T3|   500|\n",
      "|2025-01-02|    T4|   300|\n",
      "|2025-01-02|    T5|   400|\n",
      "|2025-01-02|    T6|   600|\n",
      "+----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T12:27:46.612707Z",
     "start_time": "2025-08-22T12:27:46.581686Z"
    }
   },
   "cell_type": "code",
   "source": "w = W.partitionBy(\"txn_date\").orderBy(F.col(\"amount\").desc()).rowsBetween(W.unboundedPreceding, W.unboundedFollowing)",
   "id": "139877c37188bcd2",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T12:27:48.342655Z",
     "start_time": "2025-08-22T12:27:47.970859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = df.withColumn(\n",
    "    'avg_amount',\n",
    "    F.avg(F.col(\"amount\")).over(w)\n",
    ").filter(F.col(\"amount\") > F.col(\"avg_amount\")).drop(\"avg_amount\")\n",
    "\n",
    "df.show()"
   ],
   "id": "db112451dca4bfa8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+------+\n",
      "|  txn_date|txn_id|amount|\n",
      "+----------+------+------+\n",
      "|2025-01-01|    T3|   500|\n",
      "|2025-01-02|    T6|   600|\n",
      "+----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "eb044691bcfdd01d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
