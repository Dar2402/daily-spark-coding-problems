{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c075613-f651-4c9d-bcc4-3a89f1512572",
   "metadata": {},
   "source": [
    "# üìù Problem 1: PySpark ‚Äì Calculate Rolling 3-Day Average of Sales\n",
    "\n",
    "### **Problem Statement**\n",
    "\n",
    "You have a PySpark DataFrame containing daily sales data. Write a PySpark program to **calculate the rolling 3-day average sales** for each date, ordered by the date column.\n",
    "\n",
    "### **Sample Input** (`daily_sales`)\n",
    "\n",
    "| sale\\_date | sales |\n",
    "| ---------- | ----- |\n",
    "| 2025-01-01 | 100   |\n",
    "| 2025-01-02 | 200   |\n",
    "| 2025-01-03 | 300   |\n",
    "| 2025-01-04 | 400   |\n",
    "| 2025-01-05 | 500   |\n",
    "\n",
    "### **Expected Output**\n",
    "\n",
    "| sale\\_date | sales | rolling\\_3\\_day\\_avg |\n",
    "| ---------- | ----- | -------------------- |\n",
    "| 2025-01-01 | 100   | 100.0                |\n",
    "| 2025-01-02 | 200   | 150.0                |\n",
    "| 2025-01-03 | 300   | 200.0                |\n",
    "| 2025-01-04 | 400   | 300.0                |\n",
    "| 2025-01-05 | 500   | 400.0                |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b02ad509-1765-48e4-a48f-758febe7e1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F, Window as W\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DateType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6517f0ec-7167-4693-90ca-a2da238c4476",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"DailyCodingProblem-26-08-2025\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c52546f-043a-492b-9cca-87a017041c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    (\"2025-01-01\", 100),\n",
    "    (\"2025-01-02\", 200),\n",
    "    (\"2025-01-03\", 300),\n",
    "    (\"2025-01-04\", 400),\n",
    "    (\"2025-01-05\", 500)\n",
    "]\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"sale_date\", StringType(), True),\n",
    "    StructField(\"sales\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "df = spark.createDataFrame(data, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e04bfecf-7682-4fe9-b549-d6e129d0c95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sale_date: string (nullable = true)\n",
      " |-- sales: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1919dad8-b918-43b1-adb0-cdcbcacbb2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = W.orderBy('sale_date').rowsBetween(-2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9279082d-639e-4e49-9c2c-03b6e055359a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\n",
    "    \"sale_date\",\n",
    "    F.to_date(F.col(\"sale_date\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "917e527a-016c-48ca-b7d6-94db5f355020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "| sale_date|sales|\n",
      "+----------+-----+\n",
      "|2025-01-01|  100|\n",
      "|2025-01-02|  200|\n",
      "|2025-01-03|  300|\n",
      "|2025-01-04|  400|\n",
      "|2025-01-05|  500|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e4ba452-777c-48ce-8ce7-b96f69d0ab15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----------------+\n",
      "| sale_date|sales|rolling_3_day_avg|\n",
      "+----------+-----+-----------------+\n",
      "|2025-01-01|  100|            100.0|\n",
      "|2025-01-02|  200|            150.0|\n",
      "|2025-01-03|  300|            200.0|\n",
      "|2025-01-04|  400|            300.0|\n",
      "|2025-01-05|  500|            400.0|\n",
      "+----------+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# window = Window.partitionBy(\"category\").orderBy(\"id\").rangeBetween(Window.currentRow, 1)\n",
    "# df.withColumn(\"sum\", func.sum(\"id\").over(window)).sort(\"id\", \"category\").show()\n",
    "\n",
    "\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"rolling_3_day_avg\",\n",
    "    F.avg(\"sales\").over(w)\n",
    ")\n",
    "\n",
    "df.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795cb746-9564-4484-893e-b172fcbb177d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
